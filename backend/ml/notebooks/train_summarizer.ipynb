{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Setup and Imports\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:123\u001b[0m\n\u001b[0;32m    121\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 123\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Setup and Imports\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM INFORMATION ===\n",
      "Python version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "Platform: win32\n",
      "\n",
      "=== CUDA SYSTEM CHECK ===\n",
      "NVIDIA driver found:\n",
      "Sat Apr 12 22:32:36 2025       \n",
      "\n",
      "=== UNINSTALLING CURRENT PYTORCH ===\n",
      "\n",
      "=== INSTALLING PYTORCH WITH CUDA ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "=== IMPORTANT ===\n",
      "RESTART YOUR KERNEL NOW by clicking 'Kernel > Restart Kernel'\n",
      "Then run the verification cell below in a new cell\n",
      "\n",
      "Collecting torch==2.1.0\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp311-cp311-win_amd64.whl (2722.7 MB)\n",
      "Collecting torchvision==0.16.0\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp311-cp311-win_amd64.whl (5.0 MB)\n",
      "Collecting torchaudio==2.1.0\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp311-cp311-win_amd64.whl (3.9 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.1.0) (2024.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.16.0) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.16.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.16.0) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.16.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.16.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.16.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.16.0) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.1.0+cu118 torchaudio-2.1.0+cu118 torchvision-0.16.0+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.0+cu118 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Nassi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive PyTorch CUDA Installation and Diagnosis\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# 1. Check system info\n",
    "print(\"=== SYSTEM INFORMATION ===\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "\n",
    "# 2. Check if CUDA is available on your system\n",
    "print(\"\\n=== CUDA SYSTEM CHECK ===\")\n",
    "try:\n",
    "    # Check for NVIDIA driver\n",
    "    if sys.platform == 'win32':\n",
    "        nvidia_smi = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if nvidia_smi.returncode == 0:\n",
    "            print(\"NVIDIA driver found:\")\n",
    "            print(nvidia_smi.stdout.split('\\n')[0])\n",
    "        else:\n",
    "            print(\"NVIDIA driver not found or not working\")\n",
    "    else:\n",
    "        print(\"Non-Windows platform detected, skipping nvidia-smi check\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking NVIDIA driver: {e}\")\n",
    "\n",
    "# 3. Uninstall existing PyTorch\n",
    "print(\"\\n=== UNINSTALLING CURRENT PYTORCH ===\")\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# 4. Install CUDA version with specific version\n",
    "print(\"\\n=== INSTALLING PYTORCH WITH CUDA ===\")\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# 5. Restart kernel notice\n",
    "print(\"\\n=== IMPORTANT ===\")\n",
    "print(\"RESTART YOUR KERNEL NOW by clicking 'Kernel > Restart Kernel'\")\n",
    "print(\"Then run the verification cell below in a new cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.15.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (0.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: sympy in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Nassi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Check if these are installed\n",
    "!pip install peft datasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\\nPossible CUDA issues:\")\n",
    "    print(\"1. Your NVIDIA drivers may be outdated\")\n",
    "    print(\"2. You may not have a compatible NVIDIA GPU\")\n",
    "    print(\"3. Your CUDA toolkit may not be properly installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemma 3-1B tokenizer...\n",
      "Loading Gemma 3-1B model (4-bit quantized)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1dfc119a6046e0aed8de758d2e6f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nassi\\.cache\\huggingface\\hub\\models--google--gemma-3-1b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e8ffb3a3da4fc2bb66044788421d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Setup Gemma 3-1B Model with 4-bit Quantization\n",
    "def setup_gemma_model():\n",
    "    \"\"\"Setup Gemma 3-1B model with 4-bit quantization to fit in 8GB VRAM\"\"\"\n",
    "    try:\n",
    "        # Configure 4-bit quantization for memory efficiency\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        print(\"Loading Gemma 3-1B tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "        \n",
    "        print(\"Loading Gemma 3-1B model (4-bit quantized)...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"google/gemma-3-1b-it\",\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        return model, tokenizer\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(\"1. You need to accept the Gemma model terms on Hugging Face\")\n",
    "        print(\"2. You need to be logged in with huggingface-cli login\")\n",
    "        print(\"3. Your token may not have permission to access this model\")\n",
    "        return None, None\n",
    "\n",
    "# Load the model\n",
    "model, tokenizer = setup_gemma_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TESTING IMPROVED GEMMA 3-1B ON FOOTBALL HIGHLIGHTS =====\n",
      "\n",
      "Processing highlights transcript (9933 characters)...\n",
      "\n",
      "===== SUMMARY OF HIGHLIGHTS =====\n",
      "mmary, aiming for a professional and engaging style, incorporating the transcript you provided.  I’ve focused on the key moments and nuances, aiming to capture the flow of the action and the strategic implications.\n",
      "\n",
      "---\n",
      "\n",
      "**Match Highlights: Barcelona 3 - 0 Las Palmas – A Dominant Display**\n",
      "\n",
      "**Opening Moments & Defensive Focus:**\n",
      "\n",
      "The game began with a defensive intensity. Diego Martinez & Blasparms immediately established a strong, almost suffocating, defensive shape. The initial phase saw a clear attempt to clear the ball, with a potential early challenge from the visitors.  The initial challenge was a slight hesitation, suggesting a cautious approach.\n",
      "\n",
      "**The Breakthrough – Danny Holmos Stunning Goal:**\n",
      "\n",
      "Then, with just under 10 minutes on the clock, a brilliant moment unfolded. Danny Holmes, the last Palmeiras defender, scored a stunning goal.  He sliced through the Las Palmas defense with a deft touch, landing a perfectly weighted shot that nestled into the top corner.  This was the defining moment of the first 25 minutes, instantly injecting confidence into the Barcelona side. It was a moment of pure class and skill.\n",
      "\n",
      "**(Pause for a brief moment to capture this)**\n",
      "\n",
      "**Barcelona’s Dominance Continues:**\n",
      "\n",
      "Following this goal, Barcelona continued to dictate the tempo.  Lamine Yamals and Rafinhas’s pressing was relentless.  They were relentlessly attacking the opponent’s defense, creating space and forcing mistakes.  It’s clear that the team is focused on winning the ball and applying pressure.\n",
      "\n",
      "The team’s high pressing was particularly effective, forcing errors and creating opportunities.  Barcelona's ability to maintain this level of intensity was a key factor in their success.\n",
      "\n",
      "***\n",
      "\n",
      "**Mid-Match Moments & Tactical Shifts:**\n",
      "\n",
      "* **The Switch to a Defensive Block:**  As the game progressed, the tactical approach shifted.  A clear indication of a defensive block was implemented. The defense became more compact, with players aggressively closing down space.\n",
      "* **A Quick Counterattack:**  With the ball nearing the midfield area, a quick counterattack ensued.  Ferran Torres, with an excellent touch, managed to get the ball past the defense and unleashed a powerful shot. This was a crucial moment of opportunity for Barcelona.\n",
      " * **The Offside Situation:** A moment of confusion arose when a potential offside was spotted. The referee's decision to\n"
     ]
    }
   ],
   "source": [
    "# Improved Gemma 3-1B Football Highlights Summarization\n",
    "def summarize_highlights(transcript, max_new_tokens=500):\n",
    "    \"\"\"Generate a summary of soccer highlights using Gemma 3-1B with improved soccer terminology\"\"\"\n",
    "    if model is None or tokenizer is None:\n",
    "        return \"Model not loaded correctly. Please check setup.\"\n",
    "    \n",
    "    if not transcript or len(transcript.strip()) < 50:\n",
    "        return \"Please provide a valid highlights transcript.\"\n",
    "    \n",
    "    # Create improved prompt with soccer-specific terminology guidance\n",
    "    \n",
    "    prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator with extensive experience covering major leagues. Create a concise, engaging summary of these match highlights. The transcript is from the match highlights video, some sentences may not be coherent, and there may be some errors, espically in the names of the teams or players. Make sure to use soccer-specific terminology and avoid unnecessary details. Focus on key moments, player performances, and the overall match flow. \n",
    "Use the following transcript summary as a reference:\n",
    "\"Barcelona played against Las Palmas, and the game saw several key moments. Las Palmas had a strong start, but Barcelona's defense held strong. The turning point came when Danny Holmo scored a brilliant goal, slicing through Las Palmas' defense and ending his personal goal drought. This goal was a highlight of the match, with Holmo showcasing his ability to operate in tight spaces and finish with precision.\n",
    "\n",
    "Barcelona continued to dominate, with Lamine Yamal and Rafinha creating scoring opportunities. The team's high press and ability to operate in tight spaces caused problems for Las Palmas. Although Las Palmas had some chances, Barcelona's defense was solid, and they were able to contain the opposition's attacks.\n",
    "\n",
    "In the second half, Ferran Torres scored another goal for Barcelona, securing the win with a powerful left-footed shot. The game ended with Barcelona taking all three points, thanks to their strong performance and Hansi Flick's tactical decisions. The final score was 2-0 in favor of Barcelona, with Danny Holmo and Ferran Torres scoring the goals. Danny Holmo was named MVP, and the win gave Barcelona an extra confidence boost ahead of their cup semi-finals match.\"\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{transcript}\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    #prompt2 = \"how much do you know about soccer teams and players? do you know their names? \"\n",
    "    \n",
    "    # Rest of the function remains the same\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.5,  # Reduced further for more factual output\n",
    "            top_p=0.85,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            length_penalty=1.0\n",
    "        )\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    if \"<start_of_turn>model\" in full_response:\n",
    "        summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "    else:\n",
    "        prompt_end = prompt.strip()\n",
    "        summary = full_response[len(prompt_end):].strip()\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Process the highlights transcript and display results\n",
    "print(\"===== TESTING IMPROVED GEMMA 3-1B ON FOOTBALL HIGHLIGHTS =====\\n\")\n",
    "\n",
    "if len(highlights_transcript.strip()) < 50:\n",
    "    print(\"⚠️ Please edit the cell to add your highlights transcript to the variable!\")\n",
    "else:\n",
    "    print(f\"Processing highlights transcript ({len(highlights_transcript)} characters)...\")\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarize_highlights(highlights_transcript)\n",
    "    \n",
    "    print(\"\\n===== SUMMARY OF HIGHLIGHTS =====\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adapter configuration...\n",
      "Base model: google/gemma-3-1b-it\n",
      "Using GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Available GPU memory: 8.59 GB\n",
      "Loading tokenizer...\n",
      "Generating summary...\n",
      "Generation completed in 19.63 seconds\n",
      "\n",
      "=== GENERATED SUMMARY ===\n",
      "commentator’s summary of the match, incorporating the transcript and aiming for a dynamic feel:\n",
      "\n",
      "**Blast from the Past! Barcelona Dominate, But a Late Collapse**\n",
      "\n",
      "The match between Diego Martinez and Blasparmas saw Barcelona unleash a stunning attack, but ultimately succumbed to a frustratingly defensive struggle.  The game started with a flurry of movement, with Jenny Palmer starting the defense, and Alex Sware at center back.  Early on, Martinez and Blasparmas initiated the attack, with a quick free kick from the visitors, prompting a desperate scramble for the ball.  Barcelona’s midfield, spearheaded by the dynamic Danny Omo, began to exert pressure, but the defense struggled to contain the attacking threat. \n",
      "\n",
      "The match quickly shifted momentum with a brilliant goal from Barcelona's striker, who was rewarded with a stunning flick from the right back, creating a moment of magic.  However, Barcelona’s composure started to unravel as they struggled to maintain control.  The visitors, with a mix of changes and tactical adjustments, began to press aggressively, and the defense’s defensive shape began to crumble.  \n",
      "\n",
      "A late goal from Barcelona’s winger, fueled by a brilliant run, provided a momentary spark, but the home team’s defensive solidity proved too strong.  Ultimately, a frustrating finish for Barcelona as they lost the game, leaving the door open for a thrilling Tuesday night cup final. \n",
      "\n",
      "**Final Score: Barcelona 3 – 1 Home Team**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"commentator’s summary of the match, incorporating the transcript and aiming for a dynamic feel:\\n\\n**Blast from the Past! Barcelona Dominate, But a Late Collapse**\\n\\nThe match between Diego Martinez and Blasparmas saw Barcelona unleash a stunning attack, but ultimately succumbed to a frustratingly defensive struggle.  The game started with a flurry of movement, with Jenny Palmer starting the defense, and Alex Sware at center back.  Early on, Martinez and Blasparmas initiated the attack, with a quick free kick from the visitors, prompting a desperate scramble for the ball.  Barcelona’s midfield, spearheaded by the dynamic Danny Omo, began to exert pressure, but the defense struggled to contain the attacking threat. \\n\\nThe match quickly shifted momentum with a brilliant goal from Barcelona's striker, who was rewarded with a stunning flick from the right back, creating a moment of magic.  However, Barcelona’s composure started to unravel as they struggled to maintain control.  The visitors, with a mix of changes and tactical adjustments, began to press aggressively, and the defense’s defensive shape began to crumble.  \\n\\nA late goal from Barcelona’s winger, fueled by a brilliant run, provided a momentary spark, but the home team’s defensive solidity proved too strong.  Ultimately, a frustrating finish for Barcelona as they lost the game, leaving the door open for a thrilling Tuesday night cup final. \\n\\n**Final Score: Barcelona 3 – 1 Home Team**\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple test script that avoids tensorflow dependency issues\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import time\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "\n",
    "# Model path\n",
    "model_path = \"../summarizer/models/soccer-summarizer-improved\"\n",
    "\n",
    "def test_model_gpu():\n",
    "    \"\"\"Load and test your fine-tuned model on GPU\"\"\"\n",
    "    print(\"Loading adapter configuration...\")\n",
    "    \n",
    "    # Get base model from PEFT config\n",
    "    peft_config = PeftConfig.from_pretrained(model_path)\n",
    "    base_model_name = peft_config.base_model_name_or_path\n",
    "    print(f\"Base model: {base_model_name}\")\n",
    "    \n",
    "    # Check GPU availability\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"GPU not available! This script requires CUDA.\")\n",
    "    \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load base model directly to GPU with correct dtype\n",
    "    print(\"Loading base model on GPU...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.float16,  # Keep half precision for GPU\n",
    "        device_map=\"cuda:0\"        # Explicitly use CUDA, not auto-mapping\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Load adapter\n",
    "    print(\"Loading LoRA adapter...\")\n",
    "    try:\n",
    "        model = PeftModel.from_pretrained(\n",
    "            base_model, \n",
    "            model_path,\n",
    "            is_trainable=False\n",
    "        )\n",
    "        print(\"LoRA adapter loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading adapter: {e}\")\n",
    "        print(\"Falling back to base model...\")\n",
    "        model = base_model\n",
    "    \"\"\"\n",
    "    # Test with just the base model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-3-1b-it\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"cuda:0\"\n",
    "    )\n",
    "    # Test function\n",
    "    def generate_summary(transcript, reference_teams=None, reference_players=None):\n",
    "        # Create reference text if teams and players provided\n",
    "        reference_text = \"\"\n",
    "        if reference_teams and reference_players:\n",
    "            reference_text = \"CORRECT NAMES REFERENCE:\\n\"\n",
    "            reference_text += f\"TEAMS: {', '.join(reference_teams)}\\n\"\n",
    "            reference_text += f\"PLAYERS: {', '.join(reference_players)}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator. Create a concise, engaging summary of the soccer match based on the transcript given below.\n",
    "The transcript is created through speech to text recognition which can induce errors in player and team names, correct them when possible. \n",
    "Specify at the end the final score for the match.\n",
    "\n",
    "{reference_text}\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{transcript}\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "        \n",
    "        # Measure generation time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generate summary\n",
    "        print(\"Generating summary...\")\n",
    "\n",
    "        # Prepare input and move to GPU\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=600,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "        \n",
    "        # Process output\n",
    "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if \"<start_of_turn>model\" in full_response:\n",
    "            summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        else:\n",
    "            summary = full_response[len(prompt):].strip()\n",
    "        \n",
    "        gen_time = time.time() - start_time\n",
    "        print(f\"Generation completed in {gen_time:.2f} seconds\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    # Test with a sample transcript\n",
    "    \n",
    "    \n",
    "    # Define reference teams and players\n",
    "    test_teams = [\"Barcelona\", \"Las Palmas\"]\n",
    "    test_players = [\"Danny Omo\", \"Mika Mármol\", \"Raphinha\", \"Lamine Yamal\"]\n",
    "    \n",
    "    test_teams = \"\"\n",
    "    test_players = \"\"\n",
    "    # Generate summary\n",
    "    summary = generate_summary(test_transcript, test_teams, test_players)\n",
    "    \n",
    "    print(\"\\n=== GENERATED SUMMARY ===\")\n",
    "    print(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Run the test\n",
    "test_model_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete fine-tuning pipeline for soccer match summarizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from huggingface_hub import login\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Data preparation\n",
    "# Replace with your data loading code as needed\n",
    "def load_soccer_data(data_path=None):\n",
    "    \"\"\"\n",
    "    Load the soccer transcripts dataset with 30 examples.\n",
    "    \n",
    "    If data_path is provided, it will load from that file.\n",
    "    Otherwise, use the transcripts.xlsx file from the data directory.\n",
    "    \"\"\"\n",
    "    if data_path and os.path.exists(data_path):\n",
    "        # Load from specified file path\n",
    "        if data_path.endswith('.csv'):\n",
    "            df = pd.read_csv(data_path)\n",
    "        elif data_path.endswith('.xlsx') or data_path.endswith('.xls'):\n",
    "            df = pd.read_excel(data_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {data_path}\")\n",
    "    else:\n",
    "        # Load from default dataset path\n",
    "        default_path = \"../../data/transcripts.xlsx\"\n",
    "        print(f\"Loading from default dataset path: {default_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the transcript-summary pairs from Excel\n",
    "            df = pd.read_excel(default_path)\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_cols = ['transcript', 'summary']\n",
    "            if not all(col in df.columns for col in required_cols):\n",
    "                raise ValueError(f\"Dataset must contain columns: {required_cols}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading default dataset: {e}\")\n",
    "            # print(\"Falling back to hardcoded examples...\")\n",
    "            # If default dataset fails, fall back to example data\n",
    "            # return prepare_soccer_data()\n",
    "            \n",
    "    print(f\"Loaded {len(df)} examples\")\n",
    "    \n",
    "    # Perform basic data cleaning\n",
    "    df['transcript'] = df['transcript'].astype(str).apply(lambda x: x.strip())\n",
    "    df['summary'] = df['summary'].astype(str).apply(lambda x: x.strip())\n",
    "    \n",
    "    # Remove any examples with too short content\n",
    "    min_transcript_length = 100\n",
    "    min_summary_length = 50\n",
    "    valid_df = df[(df['transcript'].str.len() > min_transcript_length) & \n",
    "                 (df['summary'].str.len() > min_summary_length)]\n",
    "    \n",
    "    if len(valid_df) < len(df):\n",
    "        print(f\"Filtered out {len(df) - len(valid_df)} examples that were too short\")\n",
    "    \n",
    "    return valid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_training(model_name=\"google/gemma-3-1b-it\"):\n",
    "    \"\"\"\n",
    "    Memory-optimized model loading for 8GB GPUs\n",
    "    \"\"\"\n",
    "    print(f\"Loading base model: {model_name}\")\n",
    "    \n",
    "    # Clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Import bitsandbytes for quantization\n",
    "    try:\n",
    "        import bitsandbytes as bnb\n",
    "    except ImportError:\n",
    "        print(\"Installing bitsandbytes...\")\n",
    "        \n",
    "        import bitsandbytes as bnb\n",
    "    \n",
    "    # QLoRA 4-bit configuration\n",
    "    from transformers import BitsAndBytesConfig\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        llm_int8_enable_fp32_cpu_offload=True,\n",
    "    )\n",
    "    \n",
    "    # Load model with extreme memory optimization\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # Even more conservative LoRA setup\n",
    "    peft_config = LoraConfig(\n",
    "        r=2,  # Reduced from 4 to 2\n",
    "        lora_alpha=4,  # Reduced from 8 to 4\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],  # Only essential attention components\n",
    "    )\n",
    "    \n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    print(f\"Trainable parameters: {model.print_trainable_parameters()}\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dataset, tokenizer, max_length=2048):\n",
    "    \"\"\"\n",
    "    Tokenize the dataset for training.\n",
    "    \"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize_function, \n",
    "        batched=True,\n",
    "        desc=\"Tokenizing data\",\n",
    "        remove_columns=[\"text\"]\n",
    "    )\n",
    "    \n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split data into train and validation sets\n",
    "def split_train_val(df, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation sets.\n",
    "    With 30 examples, a 90/10 split is reasonable.\n",
    "    \"\"\"\n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split point\n",
    "    val_count = max(1, int(len(df) * val_size))\n",
    "    \n",
    "    # Split the data\n",
    "    train_df = df[val_count:].reset_index(drop=True)\n",
    "    val_df = df[:val_count].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Split data into {len(train_df)} training and {len(val_df)} validation examples\")\n",
    "    \n",
    "    return train_df, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load team and player data from your existing datasets\n",
    "def load_soccer_knowledge():\n",
    "    \"\"\"\n",
    "    Load team and player names from your existing datasets to incorporate\n",
    "    into the model's knowledge.\n",
    "    \"\"\"\n",
    "    print(\"Loading team and player data...\")\n",
    "    \n",
    "    # Load team names from club_statistics.csv\n",
    "    teams_df = pd.read_csv(\"../../data/club_statistics.csv\")\n",
    "    team_names = teams_df[\"Club Name\"].dropna().unique().tolist()\n",
    "    print(f\"Loaded {len(team_names)} team names\")\n",
    "    \n",
    "    # Load player names from players_data_by_country_extended.csv\n",
    "    players_df = pd.read_csv(\"../../data/players_data_by_country_extended.csv\")\n",
    "    player_names = players_df[\"Player\"].dropna().unique().tolist()\n",
    "    # Limit to reasonable number to avoid overwhelming the model\n",
    "    player_names = player_names[:1000]  # Adjust this number as needed\n",
    "    print(f\"Using {len(player_names)} player names\")\n",
    "    \n",
    "    return team_names, player_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create knowledge enhancement examples\n",
    "def create_knowledge_examples(team_names, player_names, num_examples=8):\n",
    "    \"\"\"\n",
    "    Create examples that help the model learn about teams and players\n",
    "    without explicitly providing them in every prompt.\n",
    "    \"\"\"\n",
    "    knowledge_examples = []\n",
    "    \n",
    "    # Example 1: Team knowledge\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"The match between Barselona and Rel Madrid was intense. Levandoski scored for Barsa while Venicious Jr scored for Madrid.\",\n",
    "        \"summary\": \"The El Clásico between Barcelona and Real Madrid lived up to its reputation with an intense battle on the pitch. Robert Lewandowski found the net for Barcelona, while Vinícius Júnior scored for Real Madrid in this hard-fought contest.\"\n",
    "    })\n",
    "    \n",
    "    # Example 2: Premier League teams\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Mancester United faced Arsenl in a crucial match. Marcus Rasford scored for Man U while Bukayo Sako equalized for the Gunners.\",\n",
    "        \"summary\": \"Manchester United and Arsenal delivered an exciting Premier League clash. Marcus Rashford put United ahead before Bukayo Saka equalized for the Gunners in this important fixture between these historic rivals.\"\n",
    "    })\n",
    "    \n",
    "    # Example 3: Mix of leagues\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Byern Munich dominated against Dortmnd, with Harry Ken scoring a hat-trick. Jude Belingam was missed by Dortmund.\",\n",
    "        \"summary\": \"Bayern Munich claimed a commanding victory in Der Klassiker against Borussia Dortmund. Harry Kane was the star performer, netting a hat-trick. Dortmund clearly missed their former midfielder Jude Bellingham, who now plays for Real Madrid.\"\n",
    "    })\n",
    "\n",
    "    # Example 4: Champions League match\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Liverpul took on Bayern Munchen in the Champions League. Mohamed Salih scored for the Reds while Lewandoski equalized for the Germans.\",\n",
    "        \"summary\": \"Liverpool faced off against Bayern Munich in a thrilling Champions League encounter. Mohamed Salah found the net for the Reds, but Robert Lewandowski equalized for the German giants, setting up a tense finish.\"\n",
    "    })\n",
    "\n",
    "    # Example 5: La Liga match\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Atletico Madird played against Sevila. Alvaro Morata scored for Atleti while Youssef En-Nesyri equalized for the Andalusians.\",\n",
    "        \"summary\": \"Atlético Madrid clashed with Sevilla in a crucial La Liga match. Álvaro Morata put Atleti ahead, but Youssef En-Nesyri equalized for Sevilla, leaving the outcome hanging in the balance.\"\n",
    "    })\n",
    "\n",
    "    # Example 6: Serie A match\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Juventus took on Inter Milan in the Derby d'Italia. Dusan Vlahovic scored for the Bianconeri while Lautaro Martinez equalized for the Nerazzurri.\",\n",
    "        \"summary\": \"Juventus faced off against Inter Milan in the highly anticipated Derby d'Italia. Dušan Vlahović found the net for the Bianconeri, but Lautaro Martínez equalized for the Nerazzurri, setting up a thrilling conclusion to the match.\"\n",
    "    })\n",
    "\n",
    "    # Example 7: International friendly\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"France played against Argentna in a friendly match. Kylian Mbappe scored for the Blues while Lionel Messi equalized for the Albiceleste.\",\n",
    "        \"summary\": \"France took on Argentina in an exciting international friendly. Kylian Mbappé put the Blues ahead, but Lionel Messi equalized for the Albiceleste, showcasing the talent and skill of these two football powerhouses.\"\n",
    "    })\n",
    "\n",
    "    # Example 8: Premier League match\n",
    "    knowledge_examples.append({\n",
    "        \"transcript\": \"Mancester City faced Chelsie in a crucial match. Erling Haaland scored for City while Kai Havertz equalized for the Blues.\",\n",
    "        \"summary\": \"Manchester City clashed with Chelsea in a pivotal Premier League encounter. Erling Haaland found the net for City, but Kai Havertz equalized for the Blues, leaving the outcome of the match uncertain.\"\n",
    "    })\n",
    "    \n",
    "    # Add more examples that demonstrate correct name usage\n",
    "    # These will help the model learn the correct spellings without explicit lists\n",
    "    \n",
    "    return knowledge_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Updated format_data function that doesn't include explicit references\n",
    "def format_soccer_data_without_references(df):\n",
    "    \"\"\"\n",
    "    Format the data into prompt-completion pairs without explicit name references.\n",
    "    \"\"\"\n",
    "    formatted_data = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Formatting data\"):\n",
    "        # Create prompt with instructions but no reference lists\n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator. Create a concise, engaging summary of these match highlights.\n",
    "The transcript may contain speech recognition errors in player and team names - please correct them in your summary.\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{row['transcript']}\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "{row['summary']}\n",
    "<end_of_turn>\n",
    "\"\"\"\n",
    "        formatted_data.append({\"text\": prompt})\n",
    "    \n",
    "    # Convert to Dataset format\n",
    "    dataset = Dataset.from_pandas(pd.DataFrame(formatted_data))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_summarizer_model(model, tokenizer, train_dataset, val_dataset=None, output_dir=\"../summarizer/models/soccer-summarizer-improved\"):\n",
    "    \"\"\"\n",
    "    Memory-optimized training function for 8GB GPUs\n",
    "    \"\"\"\n",
    "    from transformers import get_scheduler\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # More memory-efficient training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=1,  # Reduced to 1 epoch to start\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=16,  # Increased for better stability with small batches\n",
    "        learning_rate=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        max_grad_norm=0.3,\n",
    "        warmup_ratio=0.03,\n",
    "        fp16=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        logging_steps=5,\n",
    "        evaluation_strategy=\"no\",  # Disable evaluation temporarily to save memory\n",
    "        save_strategy=\"epoch\",  # Only save at end of epoch\n",
    "        save_total_limit=1,  # Keep only the best checkpoint\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,  # Important for some models\n",
    "        # Gradient checkpointing\n",
    "        gradient_checkpointing=True,\n",
    "        # Deepspeed ZeRO-2 config for memory efficiency\n",
    "        deepspeed=\"ds_config.json\"  # You'll need to create this file\n",
    "    )\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=None,  # Disable eval temporarily\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    trainer.save_model(output_dir)\n",
    "    print(f\"Model saved to {output_dir}\")\n",
    "    \n",
    "    return trainer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save deepspeed config\n",
    "with open(\"ds_config.json\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": true,\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"allgather_partitions\": true,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": true,\n",
    "        \"reduce_scatter\": true,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"contiguous_gradients\": true\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"gradient_clipping\": 0.3,\n",
    "    \"steps_per_print\": 10\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_enhanced_training_pipeline(data_path=None):\n",
    "    \"\"\"\n",
    "    Run the complete training pipeline with proper imports and function references.\n",
    "    \"\"\"\n",
    "    # Ensure all necessary imports\n",
    "    from datasets import Dataset\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "    from transformers import DataCollatorForLanguageModeling\n",
    "    from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "    \n",
    "    # 1. Load soccer data\n",
    "    df = load_soccer_data(data_path)\n",
    "    \n",
    "    # 2. Load team and player knowledge\n",
    "    team_names, player_names = load_soccer_knowledge()\n",
    "    \n",
    "    # 3. Create knowledge enhancement examples\n",
    "    knowledge_examples = create_knowledge_examples(team_names, player_names)\n",
    "    \n",
    "    # 4. Add knowledge examples to training data\n",
    "    knowledge_df = pd.DataFrame(knowledge_examples)\n",
    "    enhanced_df = pd.concat([knowledge_df, df], ignore_index=True)\n",
    "    print(f\"Added {len(knowledge_df)} knowledge examples to {len(df)} training examples\")\n",
    "    \n",
    "    # 5. Split data for training/validation\n",
    "    train_df, val_df = split_train_val(enhanced_df, val_size=0.1)\n",
    "    \n",
    "    # 6. Format data without explicit references\n",
    "    train_dataset = format_soccer_data_without_references(train_df)\n",
    "    val_dataset = format_soccer_data_without_references(val_df)\n",
    "    \n",
    "    # 7. Prepare model and tokenizer\n",
    "    model, tokenizer = prepare_model_for_training()\n",
    "    \n",
    "    # 8. Tokenize data\n",
    "    train_tokenized = tokenize_data(train_dataset, tokenizer)\n",
    "    val_tokenized = tokenize_data(val_dataset, tokenizer)\n",
    "    \n",
    "    # 9. Train the model\n",
    "    trainer, model = train_summarizer_model(\n",
    "        model, \n",
    "        tokenizer,\n",
    "        train_tokenized, \n",
    "        val_tokenized,\n",
    "        output_dir=\"../summarizer/models/soccer-summarizer-improved\"\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer, trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Updated test function without references\n",
    "def test_enhanced_model(model_path, test_transcript):\n",
    "    \"\"\"\n",
    "    Test the trained model without providing explicit references.\n",
    "    \"\"\"\n",
    "    from peft import PeftModel, PeftConfig\n",
    "    \n",
    "    # Load the trained model\n",
    "    print(\"Loading trained model...\")\n",
    "    peft_config = PeftConfig.from_pretrained(model_path)\n",
    "    base_model_name = peft_config.base_model_name_or_path\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    \n",
    "    # Load model\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"cuda:0\"\n",
    "    )\n",
    "    \n",
    "    # Load LoRA adapter\n",
    "    model = PeftModel.from_pretrained(\n",
    "        base_model, \n",
    "        model_path,\n",
    "        is_trainable=False\n",
    "    )\n",
    "    \n",
    "    # Format prompt without references\n",
    "    prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator. Create a concise, engaging summary of these match highlights.\n",
    "The transcript may contain speech recognition errors in player and team names - please correct them in your summary.\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{test_transcript}\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate summary\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    # Extract summary\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "    \n",
    "    print(\"\\n=== GENERATED SUMMARY ===\")\n",
    "    print(summary)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from default dataset path: ../../data/transcripts.xlsx\n",
      "Loaded 30 examples\n",
      "Loading team and player data...\n",
      "Loaded 7109 team names\n",
      "Using 1000 player names\n",
      "Added 8 knowledge examples to 30 training examples\n",
      "Split data into 35 training and 3 validation examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a2aeaeaefc4e36b56410b3e7682eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting data:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7875aa702949b9bed195457831f903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting data:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: google/gemma-3-1b-it\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the entire pipeline\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model, tokenizer, trainer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_enhanced_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 33\u001b[0m, in \u001b[0;36mrun_enhanced_training_pipeline\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m format_soccer_data_without_references(val_df)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 7. Prepare model and tokenizer\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_model_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 8. Tokenize data\u001b[39;00m\n\u001b[0;32m     36\u001b[0m train_tokenized \u001b[38;5;241m=\u001b[39m tokenize_data(train_dataset, tokenizer)\n",
      "Cell \u001b[1;32mIn[46], line 8\u001b[0m, in \u001b[0;36mprepare_model_for_training\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading base model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Clear CUDA cache\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Run the entire pipeline\n",
    "model, tokenizer, trainer = run_enhanced_training_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training completes, test with a new transcript\n",
    "test_transcript = \"\"\"\n",
    "Your test transcript goes here...\n",
    "\"\"\"\n",
    "summary = test_enhanced_model(\"../summarizer/models/soccer-summarizer-improved\", test_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ../summarizer/models/soccer-summarizer-improved/checkpoint-20\n",
      "Testing with transcript from: ../../processed_videos/Las_Palmas_vs._Barcelona___LALIGA_Highlights___ESPN_FC_720.srt\n",
      "Loaded transcript (6468 chars)\n",
      "Loading base model...\n",
      "Loading LoRA adapter...\n",
      "Generating summary...\n",
      "\n",
      "=== GENERATED SUMMARY ===\n",
      "user\n",
      "You are a professional soccer commentator. Create a concise, engaging summary of these match highlights.\n",
      "The transcript may contain speech recognition errors in player and team names - please correct them in your summary.\n",
      "\n",
      "HIGHLIGHTS TRANSCRIPT:\n",
      "And this is the starting lineup for Diego Martinez and Blasparmas as you mentioned defense has been there a kill is here Will there be Marmo moving inside to play alongside Alex Sware is the captain at center back Jenny the last Palmer starting lineup Alex what do you make of Barcelona's starting lineup today most of the changes for Handsy flick in recent weeks have come in the center back pairing five different center back pairings in the last five games today It's Kubasi and Eric Garcia Only did the things to fix what was going wrong for last Palmer's early on and they seem to have turned a corner But I mentioned the Christmas a new year break Perhaps coming at the wrong time for last Palmer's because they haven't been the same team since That's free kick for the visitors We've gone 12 games on beat now in all competitions since the break it was Kunde only half away Only entirely relieving the pressure Maledo picking up the pieces for the home team and then a shot from distance which Shesney is not able to claim and But Bernie Was there an offside flag there may have been choice in goal Yeah, offside the moment that Budget he takes the shot Mac burr the last Palmer's defense already looking under duress here It's an ominous start for them in the header over the top on the angle leaning back rather unlikely move from Sheffield United It's in in his direction couldn't get a touch on it the follow-up shot is a decent one Shesney always confident it was asking just why did the goal that It was a good effort by BT and This is what you need to do if you're if you're the last Palmer's defender you need to finish the thing producing assists reading yes Now that the flags staying down for now, but for how long is the question of Sunday? And And gets the shot away Shesney There's a decent one he turned it behind You've got the high line of Barcelona. Sandro is coming from behind having a lot of side But it's sandroll the one who gets the ball. It's a very similar move Has peeled away into some space Kunde cost to meet him Here's Alberto Maledo cutting inside getting the shot away Probably three or four feet wide in the end Maledo's quality right footer player on the left he will always cut inside and tried to open an angle from shooting He tried to adjust it to the far post he went wide, but this is yet another Of course a team that never A huge amount of money to spend they got some defensive concern here as Barcelona Time made the most of this Raffinia and they didn't quite do that did he Basit working the Corner short the cross eventually arriving. It's a good hook away. Wasn't it my asu go Facing his own goal, but it breaks kindly here and the shot is on The medium out may have been a fraction offside No, it's badger these playing everyone on site It was not only for him to to try to head it, but also to call the attention of the defenders are clearing this pace for our teammates It's getting more and more involved. Does not you know now he's found Danny holmo It's absolutely brilliant Just like that they slice last Parmas open and Danny holmo Is ended his own personal gold route in some style Ability to operating tight spaces and he's the one that started the counter attack La Min Yamaha just Connecting with him in tight spaces and this This triple against Alex Bunoz Just changing the ball from the right to the left And then smashing in into the crossbar Nothing to do for Jasper Silicent what a goal. This is Danny almost quality the ability to receive the ball with one foot to switch it To the other and he had been able with technically the weaker foot To send these shots absolutely brilliant by Danny Omo These it sharp challenge there on Alex Munoz the left back which For his ignored allowing an advantage to play as a Sandro from distance Well, they don't Danny Omo just sprinting into space Providing a platform now for Balda and Rafini out feeding in towards the far post and Yamal got there But the angle was too tight drolet Beautifully done by Barcelona beating the high press that last bomb as word Trent That means you'd have used his right foot But it's all Barcelona at the moment last Parmas looking fairly ragged all of a sudden the back at Levit Dorsky unable to punish them For the knockout punch on they 20 minutes to go They really deserve it and look at the difference with Laminia Malin the first half and in the second half just paul Barci is also A part of shabby's plan of injecting more players into the first team Now Balda is trying to live in Dorsky Any bank left footed over the top No, I'm sorry. I don't know. Yeah exactly. Beatty was playing him on site All right, this isn't Sandro trying to produce a Luminium Alcross and teach us can for handball. They are the referee thinking about it And what's he gonna do here But it's almost as if he was gonna give the penalty and then realize that last Parmas Was still on the attack and that a chance might unfold. Half is the question I had the same impression as you Maybe there's an offside Is there a Garcia I think who yeah, they're appealing for the handball against what does a handball by Alex Wattip here Yeah, and then He hits the back of our of eddie I Are gonna see a last man back. This is what we want to see. This is the crucial question To answer Again still happy to just to shield possession of the attacking third 11 dosky will chase that down but not get there That's a loose clearance and a chance to finish it Ferrant Torres is not just that Another ice cold splendid finish from Barcelona That cross by Marquez Adó let's give some love and some recognition to Rafinha 95 minutes into the game and he's still Helping out the team defending chasing balls and that one touch pass makes the difference because Ferrant Torres touch is too heavy. It's not a good reception But then he makes the most of it with his left foot smashing it Into the crossbar same as Danny Omo did to secure Barcelona For this game And see flick Won't be celebrating but his team Alex are back on chop of the pile They make knocked off Briefly as it turns out by athletic overdrip The rivals are opponents of the cup race semi finals on Tuesday. So that gives them an extra confidence boost Danny Omo ending his draw and becoming the MVP Hansi flick with a perfect reading of the game and and making those substitutions Good game good second half of Barcelona great three points and At this point in performance again by last time \n",
      "\n",
      "\n",
      "model\n",
      "Okay, here's a concise soccer commentator summary of the match highlights, aiming for engaging and informative language:\n"
     ]
    }
   ],
   "source": [
    "# Load and test the existing model without training\n",
    "import os\n",
    "import re\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_transcript_from_srt(srt_path):\n",
    "    \"\"\"\n",
    "    Extract transcript text from an SRT file\n",
    "    \"\"\"\n",
    "    with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Remove SRT formatting (numbers and timestamps)\n",
    "    # Pattern matches: number, timestamp --> timestamp, then captures the text\n",
    "    srt_pattern = r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n(.*?)(?=\\n\\n\\d+\\n|$)'\n",
    "    \n",
    "    # Find all text segments\n",
    "    matches = re.findall(srt_pattern, content, re.DOTALL)\n",
    "    \n",
    "    # Combine all text into a single transcript\n",
    "    transcript = ' '.join([m.replace('\\n', ' ') for m in matches])\n",
    "    \n",
    "    return transcript\n",
    "\n",
    "def test_model_with_checkpoint(model_path, srt_path):\n",
    "    \"\"\"\n",
    "    Test the trained model using an existing SRT file\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    print(f\"Testing with transcript from: {srt_path}\")\n",
    "    \n",
    "    # Load transcript from SRT\n",
    "    transcript = load_transcript_from_srt(srt_path)\n",
    "    print(f\"Loaded transcript ({len(transcript)} chars)\")\n",
    "    \n",
    "    # Load the PEFT config\n",
    "    peft_config = PeftConfig.from_pretrained(model_path)\n",
    "    base_model_name = peft_config.base_model_name_or_path\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    \n",
    "    # Load base model\n",
    "    print(\"Loading base model...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Load LoRA adapter\n",
    "    print(\"Loading LoRA adapter...\")\n",
    "    model = PeftModel.from_pretrained(\n",
    "        base_model, \n",
    "        model_path,\n",
    "        is_trainable=False\n",
    "    )\n",
    "    \n",
    "    # Format prompt without references\n",
    "    prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator. Create a concise, engaging summary of these match highlights.\n",
    "The transcript may contain speech recognition errors in player and team names - please correct them in your summary.\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{transcript}\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate summary\n",
    "    print(\"Generating summary...\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "    \n",
    "    # Extract summary\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "    \n",
    "    print(\"\\n=== GENERATED SUMMARY ===\")\n",
    "    print(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Path to your existing SRT file\n",
    "srt_path = \"../../processed_videos/Las_Palmas_vs._Barcelona___LALIGA_Highlights___ESPN_FC_720.srt\"\n",
    "\n",
    "# Path to your trained model - checkpoint 60\n",
    "model_path = \"../summarizer/models/soccer-summarizer-improved/checkpoint-20\"\n",
    "\n",
    "# Test the model\n",
    "summary = test_model_with_checkpoint(model_path, srt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: google/gemma-3-1b-it\n",
      "\n",
      "===== Chat with Base Model =====\n",
      "Type 'exit' to end the conversation\n",
      "\n",
      "Model: user\n",
      "I'm gonna give you a soccer match transcript, in the SRT format, I want you to provide a summary of the match and at the end specify the final score, the match is between Barcelona and Las Palmas: 1 00:00:00,000 --> 00:00:06,980 And this is the starting lineup for Diego Martinez and Blasparmas as you mentioned defense has been there a kill is here  2 00:00:06,980 --> 00:00:12,240 Will there be Marmo moving inside to play alongside Alex Sware is the captain at center back  3 00:00:12,240 --> 00:00:17,839 Jenny the last Palmer starting lineup Alex what do you make of Barcelona's starting lineup today most of the changes for  4 00:00:17,839 --> 00:00:23,839 Handsy flick in recent weeks have come in the center back pairing five different center back pairings in the last five games today  5 00:00:23,839 --> 00:00:26,280 It's Kubasi and Eric Garcia  6 00:00:27,280 --> 00:00:35,120 Only did the things to fix what was going wrong for last Palmer's early on and they seem to have turned a corner  7 00:00:35,120 --> 00:00:37,719 But I mentioned the Christmas a new year break  8 00:00:39,200 --> 00:00:43,799 Perhaps coming at the wrong time for last Palmer's because they haven't been the same team since  9 00:00:46,120 --> 00:00:48,120 That's free kick for the visitors  10 00:00:49,320 --> 00:00:53,240 We've gone 12 games on beat now in all competitions since the break it was  11 00:00:54,240 --> 00:00:56,240 Kunde only half away  12 00:00:57,240 --> 00:01:05,280 Only entirely relieving the pressure Maledo picking up the pieces for the home team and then a shot from distance which Shesney is not able to claim and  13 00:01:05,280 --> 00:01:07,280 But Bernie  14 00:01:07,280 --> 00:01:11,280 Was there an offside flag there may have been choice in goal  15 00:01:14,159 --> 00:01:16,480 Yeah, offside the moment that  16 00:01:17,480 --> 00:01:23,760 Budget he takes the shot Mac burr the last Palmer's defense already looking under duress here  17 00:01:24,560 --> 00:01:30,079 It's an ominous start for them in the header over the top on the angle leaning back rather  18 00:01:31,320 --> 00:01:33,520 unlikely move from Sheffield United  19 00:01:36,439 --> 00:01:41,040 It's in in his direction couldn't get a touch on it the follow-up shot is a decent one  20 00:01:42,040 --> 00:01:46,400 Shesney always confident it was asking just why did the goal that  21 00:01:48,320 --> 00:01:50,320 It was a good effort by BT and  22 00:01:51,520 --> 00:01:58,560 This is what you need to do if you're if you're the last Palmer's defender you need to finish the thing producing assists  23 00:01:59,400 --> 00:02:01,400 reading yes  24 00:02:01,400 --> 00:02:06,040 Now that the flags staying down for now, but for how long is the question of Sunday?  25 00:02:07,040 --> 00:02:08,040 And  26 00:02:08,040 --> 00:02:09,040 And gets the shot away Shesney  27 00:02:10,040 --> 00:02:12,040 There's a decent one he turned it behind  28 00:02:13,040 --> 00:02:18,159 You've got the high line of Barcelona. Sandro is coming from behind having a lot of side  29 00:02:18,159 --> 00:02:23,040 But it's sandroll the one who gets the ball. It's a very similar move  30 00:02:24,040 --> 00:02:27,439 Has peeled away into some space Kunde cost to meet him  31 00:02:28,040 --> 00:02:31,439 Here's Alberto Maledo cutting inside getting the shot away  32 00:02:32,439 --> 00:02:35,439 Probably three or four feet wide in the end  33 00:02:37,439 --> 00:02:46,719 Maledo's quality right footer player on the left he will always cut inside and tried to open an angle from shooting  34 00:02:47,919 --> 00:02:52,000 He tried to adjust it to the far post he went wide, but this is yet another  35 00:02:53,800 --> 00:02:55,800 Of course a team that never  36 00:02:56,599 --> 00:03:00,520 A huge amount of money to spend they got some defensive concern here as Barcelona  37 00:03:01,439 --> 00:03:04,800 Time made the most of this Raffinia and they didn't quite do that did he  38 00:03:06,039 --> 00:03:08,039 Basit working the  39 00:03:08,039 --> 00:03:13,159 Corner short the cross eventually arriving. It's a good hook away. Wasn't it my asu go  40 00:03:13,639 --> 00:03:17,000 Facing his own goal, but it breaks kindly here and the shot is on  41 00:03:19,680 --> 00:03:23,280 The medium out may have been a fraction offside  42 00:03:26,639 --> 00:03:29,919 No, it's badger these playing everyone on site  43 00:03:30,079 --> 00:03:39,039 It was not only for him to to try to head it, but also to call the attention of the defenders are clearing this pace for our teammates  44 00:03:40,560 --> 00:03:44,199 It's getting more and more involved. Does not you know now he's found Danny holmo  45 00:03:47,199 --> 00:03:49,199 It's absolutely brilliant  46 00:03:50,359 --> 00:03:54,639 Just like that they slice last Parmas open and Danny holmo  47 00:03:55,639 --> 00:03:59,039 Is ended his own personal gold route in some style  48 00:04:02,319 --> 00:04:08,639 Ability to operating tight spaces and he's the one that started the counter attack La Min Yamaha just  49 00:04:09,359 --> 00:04:11,519 Connecting with him in tight spaces and this  50 00:04:12,159 --> 00:04:15,639 This triple against Alex Bunoz  51 00:04:16,800 --> 00:04:20,639 Just changing the ball from the right to the left  52 00:04:21,639 --> 00:04:25,639 And then smashing in into the crossbar  53 00:04:26,599 --> 00:04:30,719 Nothing to do for Jasper Silicent what a goal. This is  54 00:04:31,319 --> 00:04:36,680 Danny almost quality the ability to receive the ball with one foot to switch it  55 00:04:37,120 --> 00:04:41,959 To the other and he had been able with technically the weaker foot  56 00:04:42,639 --> 00:04:47,240 To send these shots absolutely brilliant by Danny Omo  57 00:04:47,960 --> 00:04:51,639 These it sharp challenge there on Alex Munoz the left back which  58 00:04:52,920 --> 00:04:57,960 For his ignored allowing an advantage to play as a Sandro from distance  59 00:05:12,040 --> 00:05:15,480 Well, they don't Danny Omo just sprinting into space  60 00:05:17,240 --> 00:05:24,360 Providing a platform now for Balda and Rafini out feeding in towards the far post and Yamal got there  61 00:05:24,360 --> 00:05:26,920 But the angle was too tight drolet  62 00:05:28,560 --> 00:05:33,199 Beautifully done by Barcelona beating the high press that last bomb as word Trent  63 00:05:34,759 --> 00:05:36,759 That means you'd have used his right foot  64 00:05:38,920 --> 00:05:45,560 But it's all Barcelona at the moment last Parmas looking fairly ragged all of a sudden the back at Levit Dorsky unable to punish them  65 00:05:47,400 --> 00:05:49,720 For the knockout punch on they 20 minutes to go  66 00:05:50,920 --> 00:05:56,840 They really deserve it and look at the difference with Laminia Malin the first half and in the second half just  67 00:05:57,400 --> 00:05:59,400 paul Barci is also  68 00:05:59,400 --> 00:06:04,040 A part of shabby's plan of injecting more players into the first team  69 00:06:04,600 --> 00:06:06,600 Now Balda is trying to live in Dorsky  70 00:06:07,879 --> 00:06:10,600 Any bank left footed over the top  71 00:06:12,040 --> 00:06:15,639 No, I'm sorry. I don't know. Yeah exactly. Beatty was playing him on site  72 00:06:16,120 --> 00:06:23,639 All right, this isn't Sandro trying to produce a Luminium Alcross and teach us can for handball. They are the referee thinking about it  73 00:06:24,680 --> 00:06:26,680 And what's he gonna do here  74 00:06:28,519 --> 00:06:32,599 But it's almost as if he was gonna give the penalty and then realize that last Parmas  75 00:06:33,560 --> 00:06:38,039 Was still on the attack and that a chance might unfold. Half is the question  76 00:06:40,199 --> 00:06:42,199 I had the same impression as you  77 00:06:43,000 --> 00:06:45,399 Maybe there's an offside  78 00:06:51,800 --> 00:06:57,800 Is there a Garcia I think who yeah, they're appealing for the handball against what does a handball by Alex Wattip here  79 00:06:58,439 --> 00:07:00,439 Yeah, and then  80 00:07:02,360 --> 00:07:04,360 He hits the back of our of eddie  81 00:07:04,439 --> 00:07:06,439 I  82 00:07:09,240 --> 00:07:13,879 Are gonna see a last man back. This is what we want to see. This is the crucial question  83 00:07:14,759 --> 00:07:16,759 To answer  84 00:07:20,280 --> 00:07:27,639 Again still happy to just to shield possession of the attacking third 11 dosky will chase that down but not get there  85 00:07:28,759 --> 00:07:31,879 That's a loose clearance and a chance to finish it  86 00:07:32,439 --> 00:07:34,439 Ferrant Torres is not just that  87 00:07:36,839 --> 00:07:41,719 Another ice cold splendid finish from Barcelona  88 00:07:43,879 --> 00:07:51,319 That cross by Marquez Adó let's give some love and some recognition to Rafinha 95 minutes into the game and he's still  89 00:07:52,040 --> 00:07:58,199 Helping out the team defending chasing balls and that one touch pass makes the difference because  90 00:07:58,519 --> 00:08:02,439 Ferrant Torres touch is too heavy. It's not a good reception  91 00:08:02,519 --> 00:08:07,159 But then he makes the most of it with his left foot smashing it  92 00:08:08,120 --> 00:08:12,920 Into the crossbar same as Danny Omo did to secure Barcelona  93 00:08:14,199 --> 00:08:16,199 For this game  94 00:08:17,319 --> 00:08:19,000 And see flick  95 00:08:19,000 --> 00:08:22,599 Won't be celebrating but his team Alex are back on chop of the pile  96 00:08:23,000 --> 00:08:24,760 They make knocked off  97 00:08:24,760 --> 00:08:27,160 Briefly as it turns out by athletic overdrip  98 00:08:28,760 --> 00:08:35,159 The rivals are opponents of the cup race semi finals on Tuesday. So that gives them an extra confidence boost  99 00:08:35,320 --> 00:08:38,840 Danny Omo ending his draw and becoming the MVP  100 00:08:40,360 --> 00:08:45,000 Hansi flick with a perfect reading of the game and and making those substitutions  101 00:08:45,639 --> 00:08:49,320 Good game good second half of Barcelona great three points and  102 00:08:49,320 --> 00:08:52,120 At this point in performance again by last time\n",
      "\n",
      "model\n",
      "Okay, here’s a summary of the match, followed by the final score and the final result:\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The match between Barcelona and Las Palmas ended 1-0 in favor of Barcelona. Diego Martinez and Blasparmas were the defenders, and the match was largely a defensive affair, with both teams struggling to create clear opportunities. Barcelona’s late goal, scored by Danny Omo, sealed the victory.  The match was a tense and tactical encounter, with both teams showing resilience and determination.\n",
      "\n",
      "**Final Score:** Barcelona 1 – Las Palmas 0\n",
      "\n",
      "**Match Result:** Barcelona wins.\n",
      "\n",
      "Model: user\n",
      "I'm gonna give you a soccer match transcript, in the SRT format, I want you to provide a summary of the match and at the end specify the final score, the match is between Barcelona and Las Palmas: 1 00:00:00,000 --> 00:00:06,980 And this is the starting lineup for Diego Martinez and Blasparmas as you mentioned defense has been there a kill is here  2 00:00:06,980 --> 00:00:12,240 Will there be Marmo moving inside to play alongside Alex Sware is the captain at center back  3 00:00:12,240 --> 00:00:17,839 Jenny the last Palmer starting lineup Alex what do you make of Barcelona's starting lineup today most of the changes for  4 00:00:17,839 --> 00:00:23,839 Handsy flick in recent weeks have come in the center back pairing five different center back pairings in the last five games today  5 00:00:23,839 --> 00:00:26,280 It's Kubasi and Eric Garcia  6 00:00:27,280 --> 00:00:35,120 Only did the things to fix what was going wrong for last Palmer's early on and they seem to have turned a corner  7 00:00:35,120 --> 00:00:37,719 But I mentioned the Christmas a new year break  8 00:00:39,200 --> 00:00:43,799 Perhaps coming at the wrong time for last Palmer's because they haven't been the same team since  9 00:00:46,120 --> 00:00:48,120 That's free kick for the visitors  10 00:00:49,320 --> 00:00:53,240 We've gone 12 games on beat now in all competitions since the break it was  11 00:00:54,240 --> 00:00:56,240 Kunde only half away  12 00:00:57,240 --> 00:01:05,280 Only entirely relieving the pressure Maledo picking up the pieces for the home team and then a shot from distance which Shesney is not able to claim and  13 00:01:05,280 --> 00:01:07,280 But Bernie  14 00:01:07,280 --> 00:01:11,280 Was there an offside flag there may have been choice in goal  15 00:01:14,159 --> 00:01:16,480 Yeah, offside the moment that  16 00:01:17,480 --> 00:01:23,760 Budget he takes the shot Mac burr the last Palmer's defense already looking under duress here  17 00:01:24,560 --> 00:01:30,079 It's an ominous start for them in the header over the top on the angle leaning back rather  18 00:01:31,320 --> 00:01:33,520 unlikely move from Sheffield United  19 00:01:36,439 --> 00:01:41,040 It's in in his direction couldn't get a touch on it the follow-up shot is a decent one  20 00:01:42,040 --> 00:01:46,400 Shesney always confident it was asking just why did the goal that  21 00:01:48,320 --> 00:01:50,320 It was a good effort by BT and  22 00:01:51,520 --> 00:01:58,560 This is what you need to do if you're if you're the last Palmer's defender you need to finish the thing producing assists  23 00:01:59,400 --> 00:02:01,400 reading yes  24 00:02:01,400 --> 00:02:06,040 Now that the flags staying down for now, but for how long is the question of Sunday?  25 00:02:07,040 --> 00:02:08,040 And  26 00:02:08,040 --> 00:02:09,040 And gets the shot away Shesney  27 00:02:10,040 --> 00:02:12,040 There's a decent one he turned it behind  28 00:02:13,040 --> 00:02:18,159 You've got the high line of Barcelona. Sandro is coming from behind having a lot of side  29 00:02:18,159 --> 00:02:23,040 But it's sandroll the one who gets the ball. It's a very similar move  30 00:02:24,040 --> 00:02:27,439 Has peeled away into some space Kunde cost to meet him  31 00:02:28,040 --> 00:02:31,439 Here's Alberto Maledo cutting inside getting the shot away  32 00:02:32,439 --> 00:02:35,439 Probably three or four feet wide in the end  33 00:02:37,439 --> 00:02:46,719 Maledo's quality right footer player on the left he will always cut inside and tried to open an angle from shooting  34 00:02:47,919 --> 00:02:52,000 He tried to adjust it to the far post he went wide, but this is yet another  35 00:02:53,800 --> 00:02:55,800 Of course a team that never  36 00:02:56,599 --> 00:03:00,520 A huge amount of money to spend they got some defensive concern here as Barcelona  37 00:03:01,439 --> 00:03:04,800 Time made the most of this Raffinia and they didn't quite do that did he  38 00:03:06,039 --> 00:03:08,039 Basit working the  39 00:03:08,039 --> 00:03:13,159 Corner short the cross eventually arriving. It's a good hook away. Wasn't it my asu go  40 00:03:13,639 --> 00:03:17,000 Facing his own goal, but it breaks kindly here and the shot is on  41 00:03:19,680 --> 00:03:23,280 The medium out may have been a fraction offside  42 00:03:26,639 --> 00:03:29,919 No, it's badger these playing everyone on site  43 00:03:30,079 --> 00:03:39,039 It was not only for him to to try to head it, but also to call the attention of the defenders are clearing this pace for our teammates  44 00:03:40,560 --> 00:03:44,199 It's getting more and more involved. Does not you know now he's found Danny holmo  45 00:03:47,199 --> 00:03:49,199 It's absolutely brilliant  46 00:03:50,359 --> 00:03:54,639 Just like that they slice last Parmas open and Danny holmo  47 00:03:55,639 --> 00:03:59,039 Is ended his own personal gold route in some style  48 00:04:02,319 --> 00:04:08,639 Ability to operating tight spaces and he's the one that started the counter attack La Min Yamaha just  49 00:04:09,359 --> 00:04:11,519 Connecting with him in tight spaces and this  50 00:04:12,159 --> 00:04:15,639 This triple against Alex Bunoz  51 00:04:16,800 --> 00:04:20,639 Just changing the ball from the right to the left  52 00:04:21,639 --> 00:04:25,639 And then smashing in into the crossbar  53 00:04:26,599 --> 00:04:30,719 Nothing to do for Jasper Silicent what a goal. This is  54 00:04:31,319 --> 00:04:36,680 Danny almost quality the ability to receive the ball with one foot to switch it  55 00:04:37,120 --> 00:04:41,959 To the other and he had been able with technically the weaker foot  56 00:04:42,639 --> 00:04:47,240 To send these shots absolutely brilliant by Danny Omo  57 00:04:47,960 --> 00:04:51,639 These it sharp challenge there on Alex Munoz the left back which  58 00:04:52,920 --> 00:04:57,960 For his ignored allowing an advantage to play as a Sandro from distance  59 00:05:12,040 --> 00:05:15,480 Well, they don't Danny Omo just sprinting into space  60 00:05:17,240 --> 00:05:24,360 Providing a platform now for Balda and Rafini out feeding in towards the far post and Yamal got there  61 00:05:24,360 --> 00:05:26,920 But the angle was too tight drolet  62 00:05:28,560 --> 00:05:33,199 Beautifully done by Barcelona beating the high press that last bomb as word Trent  63 00:05:34,759 --> 00:05:36,759 That means you'd have used his right foot  64 00:05:38,920 --> 00:05:45,560 But it's all Barcelona at the moment last Parmas looking fairly ragged all of a sudden the back at Levit Dorsky unable to punish them  65 00:05:47,400 --> 00:05:49,720 For the knockout punch on they 20 minutes to go  66 00:05:50,920 --> 00:05:56,840 They really deserve it and look at the difference with Laminia Malin the first half and in the second half just  67 00:05:57,400 --> 00:05:59,400 paul Barci is also  68 00:05:59,400 --> 00:06:04,040 A part of shabby's plan of injecting more players into the first team  69 00:06:04,600 --> 00:06:06,600 Now Balda is trying to live in Dorsky  70 00:06:07,879 --> 00:06:10,600 Any bank left footed over the top  71 00:06:12,040 --> 00:06:15,639 No, I'm sorry. I don't know. Yeah exactly. Beatty was playing him on site  72 00:06:16,120 --> 00:06:23,639 All right, this isn't Sandro trying to produce a Luminium Alcross and teach us can for handball. They are the referee thinking about it  73 00:06:24,680 --> 00:06:26,680 And what's he gonna do here  74 00:06:28,519 --> 00:06:32,599 But it's almost as if he was gonna give the penalty and then realize that last Parmas  75 00:06:33,560 --> 00:06:38,039 Was still on the attack and that a chance might unfold. Half is the question  76 00:06:40,199 --> 00:06:42,199 I had the same impression as you  77 00:06:43,000 --> 00:06:45,399 Maybe there's an offside  78 00:06:51,800 --> 00:06:57,800 Is there a Garcia I think who yeah, they're appealing for the handball against what does a handball by Alex Wattip here  79 00:06:58,439 --> 00:07:00,439 Yeah, and then  80 00:07:02,360 --> 00:07:04,360 He hits the back of our of eddie  81 00:07:04,439 --> 00:07:06,439 I  82 00:07:09,240 --> 00:07:13,879 Are gonna see a last man back. This is what we want to see. This is the crucial question  83 00:07:14,759 --> 00:07:16,759 To answer  84 00:07:20,280 --> 00:07:27,639 Again still happy to just to shield possession of the attacking third 11 dosky will chase that down but not get there  85 00:07:28,759 --> 00:07:31,879 That's a loose clearance and a chance to finish it  86 00:07:32,439 --> 00:07:34,439 Ferrant Torres is not just that  87 00:07:36,839 --> 00:07:41,719 Another ice cold splendid finish from Barcelona  88 00:07:43,879 --> 00:07:51,319 That cross by Marquez Adó let's give some love and some recognition to Rafinha 95 minutes into the game and he's still  89 00:07:52,040 --> 00:07:58,199 Helping out the team defending chasing balls and that one touch pass makes the difference because  90 00:07:58,519 --> 00:08:02,439 Ferrant Torres touch is too heavy. It's not a good reception  91 00:08:02,519 --> 00:08:07,159 But then he makes the most of it with his left foot smashing it  92 00:08:08,120 --> 00:08:12,920 Into the crossbar same as Danny Omo did to secure Barcelona  93 00:08:14,199 --> 00:08:16,199 For this game  94 00:08:17,319 --> 00:08:19,000 And see flick  95 00:08:19,000 --> 00:08:22,599 Won't be celebrating but his team Alex are back on chop of the pile  96 00:08:23,000 --> 00:08:24,760 They make knocked off  97 00:08:24,760 --> 00:08:27,160 Briefly as it turns out by athletic overdrip  98 00:08:28,760 --> 00:08:35,159 The rivals are opponents of the cup race semi finals on Tuesday. So that gives them an extra confidence boost  99 00:08:35,320 --> 00:08:38,840 Danny Omo ending his draw and becoming the MVP  100 00:08:40,360 --> 00:08:45,000 Hansi flick with a perfect reading of the game and and making those substitutions  101 00:08:45,639 --> 00:08:49,320 Good game good second half of Barcelona great three points and  102 00:08:49,320 --> 00:08:52,120 At this point in performance again by last time\n",
      "\n",
      "model\n",
      "user\n",
      "I'm gonna give you a soccer match transcript, in the SRT format, I want you to provide a summary of the match and at the end specify the final score, the match is between Barcelona and Las Palmas: 1 00:00:00,000 --> 00:00:06,980 And this is the starting lineup for Diego Martinez and Blasparmas as you mentioned defense has been there a kill is here  2 00:00:06,980 --> 00:00:12,240 Will there be Marmo moving inside to play alongside Alex Sware is the captain at center back  3 00:00:12,240 --> 00:00:17,839 Jenny the last Palmer starting lineup Alex what do you make of Barcelona's starting lineup today most of the changes for  4 00:00:17,839 --> 00:00:23,839 Handsy flick in recent weeks have come in the center back pairing five different center back pairings in the last five games today  5 00:00:23,839 --> 00:00:26,280 It's Kubasi and Eric Garcia  6 00:00:27,280 --> 00:00:35,120 Only did the things to fix what was going wrong for last Palmer's early on and they seem to have turned a corner  7 00:00:35,120 --> 00:00:37,719 But I mentioned the Christmas a new year break  8 00:00:39,200 --> 00:00:43,799 Perhaps coming at the wrong time for last Palmer's because they haven't been the same team since  9 00:00:46,120 --> 00:00:48,120 That's free kick for the visitors  10 00:00:49,320 --> 00:00:53,240 We've gone 12 games on beat now in all competitions since the break it was  11 00:00:54,240 --> 00:00:56,240 Kunde only half away  12 00:00:57,240 --> 00:01:05,280 Only entirely relieving the pressure Maledo picking up the pieces for the home team and then a shot from distance which Shesney is not able to claim and  13 00:01:05,280 --> 00:01:07,280 But Bernie  14 00:01:07,280 --> 00:01:11,280 Was there an offside flag there may have been choice in goal  15 00:01:14,159 --> 00:01:16,480 Yeah, offside the moment that  16 00:01:17,480 --> 00:01:23,760 Budget he takes the shot Mac burr the last Palmer's defense already looking under duress here  17 00:01:24,560 --> 00:01:30,079 It's an ominous start for them in the header over the top on the angle leaning back rather  18 00:01:31,320 --> 00:01:33,520 unlikely move from Sheffield United  19 00:01:36,439 --> 00:01:41,040 It's in in his direction couldn't get a touch on it the follow-up shot is a decent one  20 00:01:42,040 --> 00:01:46,400 Shesney always confident it was asking just why did the goal that  21 00:01:48,320 --> 00:01:50,320 It was a good effort by BT and  22 00:01:51,520 --> 00:01:58,560 This is what you need to do if you're if you're the last Palmer's defender you need to finish the thing producing assists  23 00:01:59,400 --> 00:02:01,400 reading yes  24 00:02:01,400 --> 00:02:06,040 Now that the flags staying down for now, but for how long is the question of Sunday?  25 00:02:07,040 --> 00:02:08,040 And  26 00:02:08,040 --> 00:02:09,040 And gets the shot away Shesney  27 00:02:10,040 --> 00:02:12,040 There's a decent one he turned it behind  28 00:02:13,040 --> 00:02:18,159 You've got the high line of Barcelona. Sandro is coming from behind having a lot of side  29 00:02:18,159 --> 00:02:23,040 But it's sandroll the one who gets the ball. It's a very similar move  30 00:02:24,040 --> 00:02:27,439 Has peeled away into some space Kunde cost to meet him  31 00:02:28,040 --> 00:02:31,439 Here's Alberto Maledo cutting inside getting the shot away  32 00:02:32,439 --> 00:02:35,439 Probably three or four feet wide in the end  33 00:02:37,439 --> 00:02:46,719 Maledo's quality right footer player on the left he will always cut inside and tried to open an angle from shooting  34 00:02:47,919 --> 00:02:52,000 He tried to adjust it to the far post he went wide, but this is yet another  35 00:02:53,800 --> 00:02:55,800 Of course a team that never  36 00:02:56,599 --> 00:03:00,520 A huge amount of money to spend they got some defensive concern here as Barcelona  37 00:03:01,439 --> 00:03:04,800 Time made the most of this Raffinia and they didn't quite do that did he  38 00:03:06,039 --> 00:03:08,039 Basit working the  39 00:03:08,039 --> 00:03:13,159 Corner short the cross eventually arriving. It's a good hook away. Wasn't it my asu go  40 00:03:13,639 --> 00:03:17,000 Facing his own goal, but it breaks kindly here and the shot is on  41 00:03:19,680 --> 00:03:23,280 The medium out may have been a fraction offside  42 00:03:26,639 --> 00:03:29,919 No, it's badger these playing everyone on site  43 00:03:30,079 --> 00:03:39,039 It was not only for him to to try to head it, but also to call the attention of the defenders are clearing this pace for our teammates  44 00:03:40,560 --> 00:03:44,199 It's getting more and more involved. Does not you know now he's found Danny holmo  45 00:03:47,199 --> 00:03:49,199 It's absolutely brilliant  46 00:03:50,359 --> 00:03:54,639 Just like that they slice last Parmas open and Danny holmo  47 00:03:55,639 --> 00:03:59,039 Is ended his own personal gold route in some style  48 00:04:02,319 --> 00:04:08,639 Ability to operating tight spaces and he's the one that started the counter attack La Min Yamaha just  49 00:04:09,359 --> 00:04:11,519 Connecting with him in tight spaces and this  50 00:04:12,159 --> 00:04:15,639 This triple against Alex Bunoz  51 00:04:16,800 --> 00:04:20,639 Just changing the ball from the right to the left  52 00:04:21,639 --> 00:04:25,639 And then smashing in into the crossbar  53 00:04:26,599 --> 00:04:30,719 Nothing to do for Jasper Silicent what a goal. This is  54 00:04:31,319 --> 00:04:36,680 Danny almost quality the ability to receive the ball with one foot to switch it  55 00:04:37,120 --> 00:04:41,959 To the other and he had been able with technically the weaker foot  56 00:04:42,639 --> 00:04:47,240 To send these shots absolutely brilliant by Danny Omo  57 00:04:47,960 --> 00:04:51,639 These it sharp challenge there on Alex Munoz the left back which  58 00:04:52,920 --> 00:04:57,960 For his ignored allowing an advantage to play as a Sandro from distance  59 00:05:12,040 --> 00:05:15,480 Well, they don't Danny Omo just sprinting into space  60 00:05:17,240 --> 00:05:24,360 Providing a platform now for Balda and Rafini out feeding in towards the far post and Yamal got there  61 00:05:24,360 --> 00:05:26,920 But the angle was too tight drolet  62 00:05:28,560 --> 00:05:33,199 Beautifully done by Barcelona beating the high press that last bomb as word Trent  63 00:05:34,759 --> 00:05:36,759 That means you'd have used his right foot  64 00:05:38,920 --> 00:05:45,560 But it's all Barcelona at the moment last Parmas looking fairly ragged all of a sudden the back at Levit Dorsky unable to punish them  65 00:05:47,400 --> 00:05:49,720 For the knockout punch on they 20 minutes to go  66 00:05:50,920 --> 00:05:56,840 They really deserve it and look at the difference with Laminia Malin the first half and in the second half just  67 00:05:57,400 --> 00:05:59,400 paul Barci is also  68 00:05:59,400 --> 00:06:04,040 A part of shabby's plan of injecting more players into the first team  69 00:06:04,600 --> 00:06:06,600 Now Balda is trying to live in Dorsky  70 00:06:07,879 --> 00:06:10,600 Any bank left footed over the top  71 00:06:12,040 --> 00:06:15,639 No, I'm sorry. I don't know. Yeah exactly. Beatty was playing him on site  72 00:06:16,120 --> 00:06:23,639 All right, this isn't Sandro trying to produce a Luminium Alcross and teach us can for handball. They are the referee thinking about it  73 00:06:24,680 --> 00:06:26,680 And what's he gonna do here  74 00:06:28,519 --> 00:06:32,599 But it's almost as if he was gonna give the penalty and then realize that last Parmas  75 00:06:33,560 --> 00:06:38,039 Was still on the attack and that a chance might unfold. Half is the question  76 00:06:40,199 --> 00:06:42,199 I had the same impression as you  77 00:06:43,000 --> 00:06:45,399 Maybe there's an offside  78 00:06:51,800 --> 00:06:57,800 Is there a Garcia I think who yeah, they're appealing for the handball against what does a handball by Alex Wattip here  79 00:06:58,439 --> 00:07:00,439 Yeah, and then  80 00:07:02,360 --> 00:07:04,360 He hits the back of our of eddie  81 00:07:04,439 --> 00:07:06,439 I  82 00:07:09,240 --> 00:07:13,879 Are gonna see a last man back. This is what we want to see. This is the crucial question  83 00:07:14,759 --> 00:07:16,759 To answer  84 00:07:20,280 --> 00:07:27,639 Again still happy to just to shield possession of the attacking third 11 dosky will chase that down but not get there  85 00:07:28,759 --> 00:07:31,879 That's a loose clearance and a chance to finish it  86 00:07:32,439 --> 00:07:34,439 Ferrant Torres is not just that  87 00:07:36,839 --> 00:07:41,719 Another ice cold splendid finish from Barcelona  88 00:07:43,879 --> 00:07:51,319 That cross by Marquez Adó let's give some love and some recognition to Rafinha 95 minutes into the game and he's still  89 00:07:52,040 --> 00:07:58,199 Helping out the team defending chasing balls and that one touch pass makes the difference because  90 00:07:58,519 --> 00:08:02,439 Ferrant Torres touch is too heavy. It's not a good reception  91 00:08:02,519 --> 00:08:07,159 But then he makes the most of it with his left foot smashing it  92 00:08:08,120 --> 00:08:12,920 Into the crossbar same as Danny Omo did to secure Barcelona  93 00:08:14,199 --> 00:08:16,199 For this game  94 00:08:17,319 --> 00:08:19,000 And see flick  95 00:08:19,000 --> 00:08:22,599 Won't be celebrating but his team Alex are back on chop of the pile  96 00:08:23,000 --> 00:08:24,760 They make knocked off  97 00:08:24,760 --> 00:08:27,160 Briefly as it turns out by athletic overdrip  98 00:08:28,760 --> 00:08:35,159 The rivals are opponents of the cup race semi finals on Tuesday. So that gives them an extra confidence boost  99 00:08:35,320 --> 00:08:38,840 Danny Omo ending his draw and becoming the MVP  100 00:08:40,360 --> 00:08:45,000 Hansi flick with a perfect reading of the game and and making those substitutions  101 00:08:45,639 --> 00:08:49,320 Good game good second half of Barcelona great three points and  102 00:08:49,320 --> 00:08:52,120 At this point in performance again by last time\n",
      "\n",
      "model\n",
      "Okay, here’s a summary of the match, followed by the final score and the final result:\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The match between Barcelona and Las Palmas ended 1-0 in favor of Barcelona. Diego Martinez and Blasparmas were the defenders, and the match was largely a defensive affair, with both teams struggling to create clear opportunities. Barcelona’s late goal, scored by Danny Omo, sealed the victory.  The match was a tense and tactical encounter, with both teams showing resilience and determination.\n",
      "\n",
      "**Final Score:** Barcelona 1 – Las Palmas 0\n",
      "\n",
      "**Match Result:** Barcelona wins.\n",
      "\n",
      "user\n",
      "ok let me see\n",
      "\n",
      "model\n",
      "Okay, let me see...\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The match between Barcelona and Las Palmas ended 1-0 in favor of Barcelona. Diego Martinez and Blasparmas were the defenders, and the match was largely a defensive affair, with both teams struggling to create clear opportunities. Barcelona’s late goal, scored by Danny Omo, sealed the victory. The match was a tense and tactical encounter, with both teams showing resilience and determination.\n",
      "\n",
      "**Final Score:** Barcelona 1 – Las Palmas 0\n",
      "\n",
      "**Match Result:** Barcelona wins.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 11.37 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m         chat_history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_response})\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Run the chat interface\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mchat_with_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m, in \u001b[0;36mchat_with_base_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     48\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Extract and clean up the response\u001b[39;00m\n\u001b[0;32m     60\u001b[0m full_response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:2326\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[0;32m   2318\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2319\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2320\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2321\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2323\u001b[0m     )\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2326\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2337\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2339\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2340\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2341\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2342\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2343\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:3286\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3283\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 3286\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3287\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:978\u001b[0m, in \u001b[0;36mGemma3ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:756\u001b[0m, in \u001b[0;36mGemma3TextModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, last_cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    743\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    744\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m         last_cache_position,\n\u001b[0;32m    754\u001b[0m     )\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 756\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_cache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_cache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:445\u001b[0m, in \u001b[0;36mGemma3DecoderLayer.forward\u001b[1;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, last_cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    443\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m position_embeddings_global\n\u001b[1;32m--> 445\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m    457\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:367\u001b[0m, in \u001b[0;36mGemma3Attention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[0;32m    366\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(query_states)\n\u001b[1;32m--> 367\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    380\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:278\u001b[0m, in \u001b[0;36meager_attention_forward\u001b[1;34m(module, query, key, value, attention_mask, dropout, scaling, softcap, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m causal_mask\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39mmodule\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    280\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 11.37 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "\n",
    "def chat_with_base_model(model_name=\"google/gemma-3-1b-it\"):\n",
    "    \"\"\"\n",
    "    Interactive chat with the base model without fine-tuning\n",
    "    \"\"\"\n",
    "    # Make sure you're logged in (needed for Gemma models)\n",
    "    # login()  # Uncomment if needed\n",
    "    \n",
    "    print(f\"Loading base model: {model_name}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Chat history - keeps context\n",
    "    chat_history = []\n",
    "    \n",
    "    print(\"\\n===== Chat with Base Model =====\")\n",
    "    print(\"Type 'exit' to end the conversation\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        # Add user message to history\n",
    "        chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # Format the entire chat history into Gemma's format\n",
    "        prompt = \"\"\n",
    "        for message in chat_history:\n",
    "            role = message[\"role\"]\n",
    "            content = message[\"content\"]\n",
    "            prompt += f\"<start_of_turn>{role}\\n{content}<end_of_turn>\\n\\n\"\n",
    "        \n",
    "        # Add the model's turn\n",
    "        prompt += \"<start_of_turn>model\\n\"\n",
    "        \n",
    "        # Generate response\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=500,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "        \n",
    "        # Extract and clean up the response\n",
    "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        model_response = full_response.split(\"<start_of_turn>model\\n\")[-1].split(\"<end_of_turn>\")[0].strip()\n",
    "        \n",
    "        # Display model response\n",
    "        print(f\"\\nModel: {model_response}\")\n",
    "        \n",
    "        # Add model response to history\n",
    "        chat_history.append({\"role\": \"model\", \"content\": model_response})\n",
    "\n",
    "# Run the chat interface\n",
    "chat_with_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: google/gemma-3-1b-it\n",
      "Model loaded successfully\n",
      "\n",
      "=== GENERATED SUMMARY ===\n",
      "user\n",
      "You are a professional soccer commentator tasked with creating concise, engaging summaries of match highlights.\n",
      "\n",
      "Context: The transcript contains speech recognition errors in player and team names - please correct these in your summary.\n",
      "\n",
      "Please summarize the following match highlights in a concise, engaging paragraph:\n",
      "\n",
      "HIGHLIGHTS TRANSCRIPT:\n",
      "And this is the starting lineup for Diego Martinez and Blasparmas as you mentioned defense has been there a kill is here Will there be Marmo moving inside to play alongside Alex Sware is the captain at center back Jenny the last Palmer starting lineup Alex what do you make of Barcelona's starting lineup today most of the changes for Handsy flick in recent weeks have come in the center back pairing five different center back pairings in the last five games today It's Kubasi and Eric Garcia Only did the things to fix what was going wrong for last Palmer's early on and they seem to have turned a corner But I mentioned the Christmas a new year break Perhaps coming at the wrong time for last Palmer's because they haven't been the same team since That's free kick for the visitors We've gone 12 games on beat now in all competitions since the break it was Kunde only half away Only entirely relieving the pressure Maledo picking up the pieces for the home team and then a shot from distance which Shesney is not able to claim and But Bernie Was there an offside flag there may have been choice in goal Yeah, offside the moment that Budget he takes the shot Mac burr the last Palmer's defense already looking under duress here It's an ominous start for them in the header over the top on the angle leaning back rather unlikely move from Sheffield United It's in in his direction couldn't get a touch on it the follow-up shot is a decent one Shesney always confident it was asking just why did the goal that It was a good effort by BT and This is what you need to do if you're if you're the last Palmer's defender you need to finish the thing producing assists reading yes Now that the flags staying down for now, but for how long is the question of Sunday? And And gets the shot away Shesney There's a decent one he turned it behind You've got the high line of Barcelona. Sandro is coming from behind having a lot of side But it's sandroll the one who gets the ball. It's a very similar move Has peeled away into some space Kunde cost to meet him Here's Alberto Maledo cutting inside getting the shot away Probably three or four feet wide in the end Maledo's quality right footer player on the left he will always cut inside and tried to open an angle from shooting He tried to adjust it to the far post he went wide, but this is yet another Of course a team that never A huge amount of money to spend they got some defensive concern here as Barcelona Time made the most of this Raffinia and they didn't quite do that did he Basit working the Corner short the cross eventually arriving. It's a good hook away. Wasn't it my asu go Facing his own goal, but it breaks kindly here and the shot is on The medium out may have been a fraction offside No, it's badger these playing everyone on site It was not only for him to to try to head it, but also to call the attention of the defenders are clearing this pace for our teammates It's getting more and more involved. Does not you know now he's found Danny holmo It's absolutely brilliant Just like that they slice last Parmas open and Danny holmo Is ended his own personal gold route in some style Ability to operating tight spaces and he's the one that started the counter attack La Min Yamaha just Connecting with him in tight spaces and this This triple against Alex Bunoz Just changing the ball from the right to the left And then smashing in into the crossbar Nothing to do for Jasper Silicent what a goal. This is Danny almost quality the ability to receive the ball with one foot to switch it To the other and he had been able with technically the weaker foot To send these shots absolutely brilliant by Danny Omo These it sharp challenge there on Alex Munoz the left back which For his ignored allowing an advantage to play as a Sandro from distance Well, they don't Danny Omo just sprinting into space Providing a platform now for Balda and Rafini out feeding in towards the far post and Yamal got there But the angle was too tight drolet Beautifully done by Barcelona beating the high press that last bomb as word Trent That means you'd have used his right foot But it's all Barcelona at the moment last Parmas looking fairly ragged all of a sudden the back at Levit Dorsky unable to punish them For the knockout punch on they 20 minutes to go They really deserve it and look at the difference with Laminia Malin the first half and in the second half just paul Barci is also A part of shabby's plan of injecting more players into the first team Now Balda is trying to live in Dorsky Any bank left footed over the top No, I'm sorry. I don't know. Yeah exactly. Beatty was playing him on site All right, this isn't Sandro trying to produce a Luminium Alcross and teach us can for handball. They are the referee thinking about it And what's he gonna do here But it's almost as if he was gonna give the penalty and then realize that last Parmas Was still on the attack and that a chance might unfold. Half is the question I had the same impression as you Maybe there's an offside Is there a Garcia I think who yeah, they're appealing for the handball against what does a handball by Alex Wattip here Yeah, and then He hits the back of our of eddie I Are gonna see a last man back. This is what we want to see. This is the crucial question To answer Again still happy to just to shield possession of the attacking third 11 dosky will chase that down but not get there That's a loose clearance and a chance to finish it Ferrant Torres is not just that Another ice cold splendid finish from Barcelona That cross by Marquez Adó let's give some love and some recognition to Rafinha 95 minutes into the game and he's still Helping out the team defending chasing balls and that one touch pass makes the difference because Ferrant Torres touch is too heavy. It's not a good reception But then he makes the most of it with his left foot smashing it Into the crossbar same as Danny Omo did to secure Barcelona For this game And see flick Won't be celebrating but his team Alex are back on chop of the pile They make knocked off Briefly as it turns out by athletic overdrip The rivals are opponents of the cup race semi finals on Tuesday. So that gives them an extra confidence boost Danny Omo ending his draw and becoming the MVP Hansi flick with a perfect reading of the game and and making those substitutions Good game good second half of Barcelona great three points and At this point in performance again by last time \n",
      "\n",
      "Create a summary that:\n",
      "1. Correctly identifies teams and players (fixing any name errors)\n",
      "2. Highlights key moments and actions\n",
      "3. Uses proper soccer terminology\n",
      "4. Has an engaging, professional tone\n",
      "\n",
      "\n",
      "model\n",
      "Okay, here’s a concise and engaging summary of the match highlights, incorporating the requested elements:\n",
      "\n",
      "“The Barcelona side secured a crucial victory against Diego Martinez and Blasparmas, showcasing a dynamic and attacking display.  The match began with a tactical shift, featuring a defensive setup prioritizing control of possession, as evidenced by the initial line-up changes.  Barcelona’s midfield, spearheaded by midfielder Alex Sware, demonstrated a strong defensive presence, punctuated by a crucial interception by Alberto Maledo, who initiated a counter-attack.  The visitors, however, proved resilient, utilizing a high press to frustrate the home team.  A brilliant strike from Sandro from distance, narrowly avoided by a deflection, ignited the attack, while Danny Omo’s clinical finish, capitalizing on a loose clearance, solidified Barcelona’s lead.  The tactical adjustments and relentless pressing from Barcelona ultimately proved decisive, showcasing a potent attacking trio and a well-executed game plan.  The match concluded with a memorable display, securing Barcelona a crucial point and solidifying their position in the cup race semi-finals, a testament to the team's tactical flexibility and individual brilliance.” \n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you'd like me to adjust the tone or focus on a specific aspect of the match!\n",
      "Model unloaded from memory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "class SummarizerService:\n",
    "    \"\"\"Service to summarize soccer match transcripts using the base Gemma model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"google/gemma-3-1b-it\", use_8bit=True):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.use_8bit = use_8bit\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the model with memory optimizations.\"\"\"\n",
    "        if self.model is not None:\n",
    "            # Model already loaded\n",
    "            return\n",
    "            \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Loading model: {self.model_name}\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        if self.use_8bit:\n",
    "            # 8-bit quantization for memory efficiency\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_8bit=True,\n",
    "                llm_int8_skip_modules=[\"embed_tokens\", \"lm_head\"]\n",
    "            )\n",
    "            \n",
    "            # Load in 8-bit mode\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                quantization_config=bnb_config,\n",
    "                device_map=\"auto\",\n",
    "                torch_dtype=torch.float16,\n",
    "                max_memory={0: \"7GiB\", \"cpu\": \"12GiB\"}\n",
    "            )\n",
    "        else:\n",
    "            # Load in FP16 mode\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            \n",
    "        print(\"Model loaded successfully\")\n",
    "    \n",
    "    def unload_model(self):\n",
    "        \"\"\"Free up GPU memory by deleting the model.\"\"\"\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            self.model = None\n",
    "            del self.tokenizer\n",
    "            self.tokenizer = None\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            print(\"Model unloaded from memory\")\n",
    "    \n",
    "    def load_transcript_from_srt(self, srt_path):\n",
    "        \"\"\"Extract transcript text from an SRT file.\"\"\"\n",
    "        with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Remove SRT formatting (numbers and timestamps)\n",
    "        srt_pattern = r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n(.*?)(?=\\n\\n\\d+\\n|$)'\n",
    "        matches = re.findall(srt_pattern, content, re.DOTALL)\n",
    "        transcript = ' '.join([m.replace('\\n', ' ') for m in matches])\n",
    "        \n",
    "        return transcript\n",
    "    \n",
    "    \"\"\"def get_soccer_knowledge(self):\n",
    "        \"Get team and player data to enhance prompt context.\"\n",
    "        # Load team data\n",
    "        team_data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'club_statistics.csv')\n",
    "        player_data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'players_data_by_country_extended.csv')\n",
    "        \n",
    "        teams = []\n",
    "        players = []\n",
    "        \n",
    "        try:\n",
    "            import pandas as pd\n",
    "            if os.path.exists(team_data_path):\n",
    "                teams_df = pd.read_csv(team_data_path)\n",
    "                if \"Club Name\" in teams_df.columns:\n",
    "                    teams = teams_df[\"Club Name\"].dropna().unique().tolist()[:20]  # Top 20 teams\n",
    "                    \n",
    "            if os.path.exists(player_data_path):\n",
    "                players_df = pd.read_csv(player_data_path)\n",
    "                if \"Player\" in players_df.columns:\n",
    "                    players = players_df[\"Player\"].dropna().unique().tolist()[:50]  # Top 50 players\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading soccer knowledge: {e}\")\n",
    "            \n",
    "        return teams, players\"\"\"\n",
    "    \n",
    "    def create_optimized_prompt(self, transcript, teams=None, players=None):\n",
    "        \"\"\"Create an optimized prompt that guides the model to produce high-quality summaries.\"\"\"\n",
    "        # Get a few important teams and players if not provided\n",
    "        # if teams is None or players is None:\n",
    "        #    teams, players = self.get_soccer_knowledge()\n",
    "            \n",
    "        # Create a knowledge-rich prompt with examples of good summarization\n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator tasked with creating concise, engaging summaries of match highlights.\n",
    "\n",
    "Context: The transcript contains speech recognition errors in player and team names - please correct these in your summary.\n",
    "\n",
    "Please summarize the following match highlights in a concise, engaging paragraph:\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{transcript}\n",
    "\n",
    "Create a summary that:\n",
    "1. Correctly identifies teams and players (fixing any name errors)\n",
    "2. Highlights key moments and actions\n",
    "3. Uses proper soccer terminology\n",
    "4. Has an engaging, professional tone\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def summarize(self, transcript, max_length=250):\n",
    "        \"\"\"Generate a summary for the given transcript.\"\"\"\n",
    "        # Load model if not already loaded\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "            \n",
    "        # Create optimized prompt\n",
    "        prompt = self.create_optimized_prompt(transcript)\n",
    "        \n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "            \n",
    "        # Extract generated summary\n",
    "        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        \n",
    "        # Optionally free memory after generation\n",
    "        # self.unload_model()\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def summarize_from_file(self, srt_path, max_length=500):\n",
    "        \"\"\"Generate a summary from an SRT file.\"\"\"\n",
    "        transcript = self.load_transcript_from_srt(srt_path)\n",
    "        return self.summarize(transcript, max_length)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to a transcript file\n",
    "    srt_path = \"../../processed_videos/Las_Palmas_vs._Barcelona___LALIGA_Highlights___ESPN_FC_720.srt\"\n",
    "    \n",
    "    # Create summarizer service\n",
    "    summarizer = SummarizerService(use_8bit=True)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarizer.summarize_from_file(srt_path)\n",
    "    print(\"\\n=== GENERATED SUMMARY ===\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Unload model when done\n",
    "    summarizer.unload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "class GemmaSummarizerService:\n",
    "    \"\"\"Service to summarize soccer match transcripts using the base Gemma model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"google/gemma-3-1b-it\", use_8bit=True):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.use_8bit = use_8bit\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the model with memory optimizations.\"\"\"\n",
    "        if self.model is not None:\n",
    "            # Model already loaded\n",
    "            return\n",
    "            \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Loading model: {self.model_name}\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        if self.use_8bit:\n",
    "            # 8-bit quantization for memory efficiency\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_8bit=True,\n",
    "                llm_int8_skip_modules=[\"embed_tokens\", \"lm_head\"]\n",
    "            )\n",
    "            \n",
    "            # Load in 8-bit mode\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                quantization_config=bnb_config,\n",
    "                device_map=\"auto\",\n",
    "                torch_dtype=torch.float16,\n",
    "                max_memory={0: \"7GiB\", \"cpu\": \"12GiB\"}\n",
    "            )\n",
    "        else:\n",
    "            # Load in FP16 mode\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            \n",
    "        print(\"Model loaded successfully\")\n",
    "    \n",
    "    def unload_model(self):\n",
    "        \"\"\"Free up GPU memory by deleting the model.\"\"\"\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            self.model = None\n",
    "            del self.tokenizer\n",
    "            self.tokenizer = None\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            print(\"Model unloaded from memory\")\n",
    "    \n",
    "    def load_transcript_from_srt(self, srt_path):\n",
    "        \"\"\"Extract transcript text from an SRT file.\"\"\"\n",
    "        with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Remove SRT formatting (numbers and timestamps)\n",
    "        srt_pattern = r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n(.*?)(?=\\n\\n\\d+\\n|$)'\n",
    "        matches = re.findall(srt_pattern, content, re.DOTALL)\n",
    "        transcript = ' '.join([m.replace('\\n', ' ') for m in matches])\n",
    "        \n",
    "        return transcript\n",
    "    \n",
    "    def create_optimized_prompt(self, transcript):\n",
    "        \"\"\"Create an optimized prompt that guides the model to produce high-quality summaries.\"\"\"\n",
    "        prompt = f\"\"\"<start_of_turn>user\n",
    "You are a professional soccer commentator tasked with creating concise, engaging summaries of match highlights.\n",
    "\n",
    "Context: The transcript contains speech recognition errors in player and team names - please correct these in your summary.\n",
    "\n",
    "Please summarize the following match highlights in a concise, engaging paragraph:\n",
    "\n",
    "HIGHLIGHTS TRANSCRIPT:\n",
    "{transcript}\n",
    "\n",
    "Create a summary that:\n",
    "1. Correctly identifies teams and players (fixing any name errors)\n",
    "2. Highlights key moments and actions\n",
    "3. Uses proper soccer terminology\n",
    "4. Has an engaging, professional tone\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def summarize(self, transcript, max_length=500):\n",
    "        \"\"\"Generate a summary for the given transcript.\"\"\"\n",
    "        # Load model if not already loaded\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "            \n",
    "        # Create optimized prompt\n",
    "        prompt = self.create_optimized_prompt(transcript)\n",
    "        \n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                do_sample=True\n",
    "            )\n",
    "            \n",
    "        # Extract generated summary\n",
    "        full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        summary = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def summarize_from_file(self, srt_path, max_length=500):\n",
    "        \"\"\"Generate a summary from an SRT file.\"\"\"\n",
    "        transcript = self.load_transcript_from_srt(srt_path)\n",
    "        return self.summarize(transcript, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitsandbytes version: 0.45.5\n",
      "Quantization is available: True\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "# Better version check that handles missing __version__ attribute\n",
    "try:\n",
    "    version = bnb.__version__\n",
    "    print(f\"bitsandbytes version: {version}\")\n",
    "except AttributeError:\n",
    "    # Try alternative approaches to get version\n",
    "    try:\n",
    "        import pkg_resources\n",
    "        version = pkg_resources.get_distribution(\"bitsandbytes\").version\n",
    "        print(f\"bitsandbytes version: {version}\")\n",
    "    except:\n",
    "        print(\"bitsandbytes is installed (version information not available)\")\n",
    "\n",
    "# Confirm the module is working by checking for a key function\n",
    "print(f\"Quantization is available: {hasattr(bnb, 'nn')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.50.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nassi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Nassi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Nassi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
